# ğŸ§  LLM Chatbot Framework â€“ RAG Pipeline Overview

This repository demonstrates the foundational components of an LLM-powered chatbot using a Retrieval-Augmented Generation (RAG) architecture.

## ğŸ”§ Components Overview

### 1. ğŸ“¦ Output Parser
- **Purpose**: Converts LLM-generated text into a structured format (JSON, list, dict, etc.)
- **Use case**: Helps enforce consistent formatting for downstream processing (e.g., QA pairs, tables).
- **Tools**: `LangChain OutputParser`, `PydanticOutputParser`, `RegexParser`

### 2. âœ‚ï¸ Chunking
- **Purpose**: Breaks large documents into manageable pieces for embedding & retrieval.
- **Strategies**:
  - Fixed-size chunking (e.g., 500 tokens)
  - Overlapping windows (e.g., 500 tokens with 50 overlap)
  - Semantic chunking (based on headers or topic shifts)
- **Tools**: `LangChain TextSplitter`, `RecursiveCharacterTextSplitter`

### 3. ğŸ“š Vector Database (Vector DB)
- **Purpose**: Stores document chunks as vector embeddings for semantic search.
- **Workflow**:
  - Text â†’ Embeddings â†’ Stored in vector DB
  - Query â†’ Embedding â†’ Nearest neighbors â†’ Retrieved chunks
- **Common Vector DBs**:
  - `FAISS` (local)
  - `ChromaDB`
  - `Pinecone`, `Weaviate` (hosted)

### 4. ğŸ¤– Chatbot
- **Purpose**: Enables conversation interface for users to ask questions based on stored knowledge.
- **Workflow**:
  - User query â†’ Query transformation â†’ Vector DB search â†’ LLM â†’ Answer
- **Tools**:
  - `Streamlit` for UI
  - `LangChain ConversationalRetrievalChain`
  - `Ollama` / `HuggingFace` / `OpenAI` for LLM backend

### 5. ğŸ”„ Query Transformation
- **Purpose**: Reformulates user queries to better match context/document structure.
- **Examples**:
  - Convert "Tell me about policies" â†’ "Summarize the company HR policies."
- **Tools**:
  - `PromptTemplates` + LLM-based rewriters
  - Query Rewriter Chains in LangChain
